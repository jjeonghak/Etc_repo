# 웹사이트 주소
1. 소통방식 : https://
2. 도메인 이름 : www.google.com
3. 경로 : /catalog/news
4. 쿼리 스트링(파라미터) : ?sorting=price&pageNumber=4  # price기준으로 정렬된 4페이지
   위치 지정 : #Degugging  # 특정위치로

# 서버에 요청
import requests
requests.get("web_site")  # 데이터 타입 response
requests.get("web_site").text  # 웹사이트의 html 파일 출력

# 파싱(Parsing)
문자의 구조를 분석해서 원하는 정보를 얻어내는 것
1. 해당 사이트 html text파일 불러오기
2. text파일 BeautifulSoup 타입으로 변경
3. 원하는 정보가 들어있는 tag 선택
4. 선택한 tag에 들어있는 text만 리스트로 추가

from bs4 import BeautifulSoup
html_code = requests.get("web_site").text
soup = BeautifulSoup(html_code, 'html.parser')  # BeautifulSoup 타입으로 변환
select_tags = soup.select('tag')  # css선택자를 넣으면 특정 html 태그만 선택
- 태그에 .text를 붙이면 텍스트 추출, ["속성 이름"]을 붙이면 해당 속성의 값 추출
  img_tags = soup.select('img')  # 모든 <img> 태그 선택
  print(img_tags[0]["src"])  # 첫 번째 요소의 "src" 속성 값 가져오기

tag_text = []
for i in select_tags:  # 원하는 태그만 선택한 요소 중
   tag_text.append(i.text)  # 리스트에 태그에 속한 텍스트만 추가

# 페이지 가져오기
실제로 데이터가 존재하는 페이지와 그렇지 않은 페이지 비교, 데이터 없는 페이지의 특징 클래스 탐색
데이터가 없는 페이지는 ".csrch_tip" 클래스 존재한다고 가정(상황에 맞게)
import time
import requests
from bs4 import BeautifulSoup

pages = []  # 빈 리스트 생성
page_num = 1  # 첫 페이지 번호 지정

while True:
    response = requests.get("web_site" + str(page_num))
    soup = BeautifulSoup(response.text, 'html.parser')
    if len(soup.select('.csrch_tip')) == 0:  # ".csrch_tip" 클래스가 없을 때만 
        pages.append(soup)
        page_num += 1
        time.sleep(3)  # 지속적으로 할 경우 차단당할 우려
    else:
        break

